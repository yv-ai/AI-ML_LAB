# Import necessary libraries
import numpy as np
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# 1. Load the Dataset
data = load_iris()
X = data.data  # Selecting only features
y = data.target  # Labels for the dataset (optional for PCA)

# 2. Standardize the Data
# Ensure each feature has a mean of 0 and standard deviation of 1
scaler = StandardScaler()
X_standardized = scaler.fit_transform(X)

# 3. Calculate Covariance Matrix
cov_matrix = np.cov(X_standardized, rowvar=False)

# 4. Find Eigenvalues and Eigenvectors
# Perform eigen decomposition to get principal components
eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)

# 5. Choose the Number of Components
# Calculate explained variance and sort eigenvalues and eigenvectors
explained_variances = eigenvalues / np.sum(eigenvalues)
sorted_indices = np.argsort(eigenvalues)[::-1]
eigenvalues_sorted = eigenvalues[sorted_indices]
eigenvectors_sorted = eigenvectors[:, sorted_indices]

# Select top components (e.g., top 2 for visualization)
top_k = 2
eigenvectors_selected = eigenvectors_sorted[:, :top_k]

# 6. Transform the Data
# Project data onto the new lower-dimensional space
X_pca = X_standardized.dot(eigenvectors_selected)

# 7. Visualize the Results
# Plot the transformed data in the 2D space
plt.figure(figsize=(8, 6))
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', edgecolor='k', s=50)
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('PCA on Iris Dataset')
plt.colorbar(label='Target Label')
plt.show()
